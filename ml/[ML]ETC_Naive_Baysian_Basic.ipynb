{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 나이브 베이즈 분류기 기본\n",
    "\n",
    "## 2018년 1월 1일 안상호 \n",
    "\n",
    "## 1. 모델 \n",
    "[조대협의 블로그](http://bcho.tistory.com/1010)\n",
    "\n",
    "`word`가 주어졌을 때, `Category` 예측 이진 분류\n",
    "\n",
    "$${\\displaystyle p(c_1|d)={\\frac {p(c_1, d)}{p(d)}}={\\frac {p(d|c_1)p(c_1)}{p(d)}}}$$\n",
    "$${\\displaystyle p(c_2|d)={\\frac {p(d|c_2)p(c_2)}{p(d)}}}$$\n",
    "\n",
    "### 필요한 것들\n",
    "\n",
    "1. $P(Comedy)$, $P(Action)$\n",
    "2. $P(word|Comedy)$, $P(word|Action)$\n",
    "\n",
    "### 1.1. $P(Comedy)$, $P(Action)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie</th>\n",
       "      <th>word</th>\n",
       "      <th>Rec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>fun, couple, love, love</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>fast, furious, shoot</td>\n",
       "      <td>Action</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>couple, fly, fast, fun, fun</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>furious, shoot, shoot, fun</td>\n",
       "      <td>Action</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>fly, fast, shoot, love</td>\n",
       "      <td>Action</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movie                         word     Rec\n",
       "0      1      fun, couple, love, love  Comedy\n",
       "1      2         fast, furious, shoot  Action\n",
       "2      3  couple, fly, fast, fun, fun  Comedy\n",
       "3      4   furious, shoot, shoot, fun  Action\n",
       "4      5       fly, fast, shoot, love  Action"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "review = pd.read_csv(\"data/naive_ex.csv\", encoding=\"utf8\")\n",
    "\n",
    "review.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3)\n"
     ]
    }
   ],
   "source": [
    "total = review.shape[0]\n",
    "num_Comedy = sum(review[\"Rec\"] == \"Comedy\")\n",
    "num_Action = total - num_Comedy\n",
    "\n",
    "print(num_Comedy,num_Action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.4, 0.6)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "\n",
    "P_C = num_Comedy/total\n",
    "P_A = num_Action/total\n",
    "print(P_C, P_A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. $P(word|Comedy)$, $P(word|Action)$\n",
    "\n",
    "#### $P(word|Comedy)$\n",
    "\n",
    "$P(word, Comedy)$\n",
    "\n",
    "- word 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def review_to_wordlist(review, remove_stopwords = False):\n",
    "    # review_text = re.sub(\"Review \", \"\", review)\n",
    "    review_text = BeautifulSoup(review).get_text() # 텍스트 추출\n",
    "    review_text = re.sub(\" [^a-zA-Z]\", \" \", review_text) # 기호문자 제거\n",
    "    words = review_text.lower().split() # 소문자 변환 후 분리\n",
    "    \n",
    "    if remove_stopwords:\n",
    "        stops = set(stopwords.words(\"english\"))\n",
    "        words = [w for w in words if not w in stops]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk.data\n",
    "nltk.download('punkt')\n",
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "\n",
    "# 토크나이즈 함수생성(리뷰->토큰)\n",
    "def review_to_sentences(review, tokenizer, remove_stopwords = False):\n",
    "    # 1. 문단을 문장으로 스플릿\n",
    "    raw_sentences = tokenizer.tokenize(review.strip())\n",
    "    \n",
    "    # 2. 문장들을 빈리스트에 하나씩 추가\n",
    "    sentences = []\n",
    "    for raw_sentence in raw_sentences:\n",
    "        if len(raw_sentence) > 0: # 비어있는 문장은 스킵\n",
    "            sentences.append(review_to_wordlist(raw_sentence, remove_stopwords))\n",
    "    return sentences # (each sentence is a list of words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing sentences from review_set\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'strip'",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-110-5e9660f86da8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Parsing sentences from review_set\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrev\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreview\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"rev_text\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0msentences\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mreview_to_sentences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-106-ccd26b91a7f1>\u001b[0m in \u001b[0;36mreview_to_sentences\u001b[0;34m(review, tokenizer, remove_stopwords)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mreview_to_sentences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreview\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremove_stopwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# 1. 문단을 문장으로 스플릿\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mraw_sentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreview\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# 2. 문장들을 빈리스트에 하나씩 추가\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'float' object has no attribute 'strip'"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "sentences = []\n",
    "\n",
    "print(\"Parsing sentences from review_set\")\n",
    "for rev in review[\"rev_text\"]:\n",
    "    sentences += review_to_sentences(rev, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'fun', u'couple', u'love', u'love']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({u'fun': 3, u'fly': 1, u'couple': 2, u'love': 2, u'fast': 1}, 9)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "Comedy_df = review[review[\"Rec\"] == \"Comedy\"].copy()\n",
    "\n",
    "word_num = 0\n",
    "word_count_dict = {}\n",
    "for i in Comedy_df.index:\n",
    "    a = sentences[i]\n",
    "        \n",
    "    for w in set(a):\n",
    "        try:\n",
    "            word_count_dict[w] += a.count(w)\n",
    "        except:\n",
    "            word_count_dict[w] = a.count(w)\n",
    "#         print(w,a.count(w))    \n",
    "    word_num += len(a)\n",
    "\n",
    "print(word_count_dict, word_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'couple', 'fast', 'fly', 'fun'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set([\"couple\", \"fly\", \"fast\", \"fun\", \"fun\"])\n",
    "set([\"fun\", \"couple\", \"love\", \"love\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count를 했으니 DF로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "      <th>P_w_C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fun</td>\n",
       "      <td>3</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fly</td>\n",
       "      <td>1</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>couple</td>\n",
       "      <td>2</td>\n",
       "      <td>0.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>love</td>\n",
       "      <td>2</td>\n",
       "      <td>0.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fast</td>\n",
       "      <td>1</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     word  count     P_w_C\n",
       "0     fun      3  0.333333\n",
       "1     fly      1  0.111111\n",
       "2  couple      2  0.222222\n",
       "3    love      2  0.222222\n",
       "4    fast      1  0.111111"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "term_df = pd.DataFrame()\n",
    "term_df[\"word\"] = word_count_dict.keys()\n",
    "term_df[\"count\"] = word_count_dict.values()\n",
    "term_df[\"P_w_C\"] = term_df[\"count\"]/word_num\n",
    "term_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. 함수화\n",
    "\n",
    "### 2.1. $P(Comedy)$, $P(Action)$ 이진 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rev_date</th>\n",
       "      <th>rev_text</th>\n",
       "      <th>rev_helpful</th>\n",
       "      <th>rev_games</th>\n",
       "      <th>rev_recommend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24 January</td>\n",
       "      <td>Things I Have Never Done in GTA Online Used Ha...</td>\n",
       "      <td>3 039 of 3 280 people  93   found this re...</td>\n",
       "      <td>133.0</td>\n",
       "      <td>Not Recommended</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28 February</td>\n",
       "      <td>600 hours Great game Came back on to have some...</td>\n",
       "      <td>1 347 of 1 465 people  92   found this re...</td>\n",
       "      <td>163.0</td>\n",
       "      <td>Not Recommended</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23 January</td>\n",
       "      <td>Banned in the middle of a game for no reason w...</td>\n",
       "      <td>806 of 889 people  91   found this review...</td>\n",
       "      <td>38.0</td>\n",
       "      <td>Not Recommended</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30 August  2016</td>\n",
       "      <td>Let me start at the beginning in order to accu...</td>\n",
       "      <td>1 548 of 1 699 people  91   found this re...</td>\n",
       "      <td>87.0</td>\n",
       "      <td>Not Recommended</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21 January</td>\n",
       "      <td>I used to love this game so much I ve played m...</td>\n",
       "      <td>874 of 965 people  91   found this review...</td>\n",
       "      <td>81.0</td>\n",
       "      <td>Not Recommended</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            rev_date                                           rev_text  \\\n",
       "0         24 January  Things I Have Never Done in GTA Online Used Ha...   \n",
       "1        28 February  600 hours Great game Came back on to have some...   \n",
       "2         23 January  Banned in the middle of a game for no reason w...   \n",
       "3    30 August  2016  Let me start at the beginning in order to accu...   \n",
       "4         21 January  I used to love this game so much I ve played m...   \n",
       "\n",
       "                                         rev_helpful  rev_games  \\\n",
       "0       3 039 of 3 280 people  93   found this re...      133.0   \n",
       "1       1 347 of 1 465 people  92   found this re...      163.0   \n",
       "2       806 of 889 people  91   found this review...       38.0   \n",
       "3       1 548 of 1 699 people  91   found this re...       87.0   \n",
       "4       874 of 965 people  91   found this review...       81.0   \n",
       "\n",
       "     rev_recommend  \n",
       "0  Not Recommended  \n",
       "1  Not Recommended  \n",
       "2  Not Recommended  \n",
       "3  Not Recommended  \n",
       "4  Not Recommended  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "review = pd.read_csv(\"data/steam_GTA5_review.csv\", encoding=\"utf8\")\n",
    "review.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'Action', u'Comedy']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def Prob_Class(data, Class_colName):\n",
    "    rowNum = data.shape[0] \n",
    "    Class_set = set(data[Class_colName])\n",
    "    Class_total_dict = {}\n",
    "    \n",
    "    for class_elem in Class_set:\n",
    "        Class_total_dict[class_elem] = (sum(data[Class_colName] == class_elem))/rowNum\n",
    "    return Class_total_dict\n",
    "\n",
    "Prob_Class(review, \"Rec\").keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. $P(word|Comedy)$, $P(word|Action)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from nltk.corpus import stopwords\n",
    "import nltk.data\n",
    "import re\n",
    "\n",
    "nltk.download('punkt')\n",
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "\n",
    "def review_to_wordlist(review, remove_stopwords = False):\n",
    "    # review_text = re.sub(\"Review \", \"\", review)\n",
    "    review_text = BeautifulSoup(review).get_text() # 텍스트 추출\n",
    "    review_text = re.sub(\" [^a-zA-Z]\", \" \", review_text) # 기호문자 제거\n",
    "    review_text = re.sub(',','', review_text)\n",
    "    words = review_text.lower().split() # 소문자 변환 후 분리\n",
    "    \n",
    "    if remove_stopwords:\n",
    "        stops = set(stopwords.words(\"english\"))\n",
    "        words = [w for w in words if not w in stops]\n",
    "    return words\n",
    "\n",
    "# 토크나이즈 함수생성(리뷰->토큰)\n",
    "def review_to_sentences(review, tokenizer, remove_stopwords = False):\n",
    "    # 1. 문단을 문장으로 스플릿\n",
    "    raw_sentences = tokenizer.tokenize(review.strip())\n",
    "    \n",
    "    # 2. 문장들을 빈리스트에 하나씩 추가\n",
    "    sentences = []\n",
    "    for raw_sentence in raw_sentences:\n",
    "        if len(raw_sentence) > 0: # 비어있는 문장은 스킵\n",
    "            sentences.append(review_to_wordlist(raw_sentence, remove_stopwords))\n",
    "    return sentences # (each sentence is a list of words)\n",
    "\n",
    "def train_Baysian(data, Text_colName, Class_colName, Class_dict):\n",
    "    \n",
    "    ### 텍스트 데이터 전처리 \n",
    "    sentences = []\n",
    "    for d in data[Text_colName]:\n",
    "        sentences += review_to_sentences(d, tokenizer)\n",
    "        \n",
    "    ### ㅁㅁ\n",
    "    \n",
    "    for class_elem in Class_dict.keys():\n",
    "        \n",
    "        Class_df = data[data[Class_colName] == class_elem].copy()\n",
    "        word_num, word_count_dict = 0, {}\n",
    "        \n",
    "        for i in Class_df.index:\n",
    "            a = sentences[i]\n",
    "\n",
    "            for w in set(a):\n",
    "                try:\n",
    "                    word_count_dict[w] += a.count(w)\n",
    "                except:\n",
    "                    word_count_dict[w] = a.count(w)\n",
    "        #         print(w,a.count(w))    \n",
    "            word_num += len(a)\n",
    "        print(word_count_dict, word_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'strip'",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-98-2c2b4cb33e62>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m               \u001b[0mText_colName\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"rev_text\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m               \u001b[0mClass_colName\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"rev_recommend\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m               Class_dict = Prob_Class(review, \"rev_recommend\"))\n\u001b[0m",
      "\u001b[0;32m<ipython-input-95-003574aa760d>\u001b[0m in \u001b[0;36mtrain_Baysian\u001b[0;34m(data, Text_colName, Class_colName, Class_dict)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mText_colName\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0msentences\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mreview_to_sentences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;31m### ㅁㅁ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-95-003574aa760d>\u001b[0m in \u001b[0;36mreview_to_sentences\u001b[0;34m(review, tokenizer, remove_stopwords)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mreview_to_sentences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreview\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremove_stopwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;31m# 1. 문단을 문장으로 스플릿\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mraw_sentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreview\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;31m# 2. 문장들을 빈리스트에 하나씩 추가\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'float' object has no attribute 'strip'"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "# train_Baysian(data = review, \n",
    "#               Text_colName = \"word\", \n",
    "#               Class_colName = \"Rec\", \n",
    "#               Class_dict = Prob_Class(review, \"Rec\"))\n",
    "\n",
    "train_Baysian(data = review, \n",
    "              Text_colName = \"rev_text\", \n",
    "              Class_colName = \"rev_recommend\", \n",
    "              Class_dict = Prob_Class(review, \"rev_recommend\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action\n",
      "Comedy\n"
     ]
    }
   ],
   "source": [
    "for class_elem in Prob_Class(review, \"Rec\").keys():\n",
    "    print(class_elem)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
